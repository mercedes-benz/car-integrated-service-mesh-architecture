{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARISMA: Structured Search for Related Approaches\n",
    "\n",
    "| Database | Query |\n",
    "| ----------- | ----------- |\n",
    "| General | (Automotive OR Vehicle OR SDV) AND (SOA OR \"Service-Oriented Architecture\") NOT Study NOT Survey NOT Review NOT Comparison |\n",
    "| IEEE Xplore | (\"All Metadata\":Automotive OR \"All Metadata\":Vehicle OR \"All Metadata\":SDV) AND (\"All Metadata\":SOA OR \"All Metadata\":\"Service-Oriented Architecture\") NOT (\"Document Title\":Survey) NOT (\"Document Title\":Study) NOT (\"Document Title\":Review) NOT (\"Document Title\":Comparison) |\n",
    "| Google Scholar | (Automotive OR Vehicle OR SDV) AND (SOA OR \"Service-Oriented Architecture\") AND -Study AND -Survey AND -Comparison |\n",
    "| DBLP 1 | Automotive\\|Vehicle\\|SDV SOA |\n",
    "| DBLP 2 | Automotive\\|Vehicle\\|SDV Service Oriented |\n",
    "| ACM | AllField:(Automotive OR Vehicle OR SDV) AND AllField:(SOA OR \"Service-Oriented Architecture\") AND Title:(!Survey AND !Study AND !Review AND !Comparison) |\n",
    "| SCOPUS | TITLE-ABS-KEY ((Automotive OR Vehicle OR SDV) AND (SOA OR \"Service-Oriented Architecture\" )) AND PUBYEAR > 2020 AND NOT TITLE (Survey OR Study OR Review OR Comparison) AND (LIMIT-TO (SUBJAREA, \"ENGI\") OR LIMIT-TO(SUBJAREA, \"COMP\")) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import urlencode\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import bibtexparser\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import pybliometrics\n",
    "from pybliometrics.scopus import ScopusSearch\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "import requests\n",
    "\n",
    "from constants import KEY_ELSEVIER\n",
    "from constants import KEY_IEEE_XPLORE\n",
    "from constants import RESULTS_LIMIT\n",
    "from constants import YEAR_START\n",
    "from xploreapi import XPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_on_ieee_xplore(query, offset = 0):\n",
    "    x = XPLORE(KEY_IEEE_XPLORE)\n",
    "\n",
    "    x.queryText(query)\n",
    "    x.resultsFilter(\"start_year\", YEAR_START)\n",
    "    x.startingResult(offset)\n",
    "    x.maximumResults(RESULTS_LIMIT)\n",
    "    x.dataType(\"json\")\n",
    "\n",
    "    data = x.callAPI()\n",
    "    data = json.loads(data)\n",
    "\n",
    "    paper = []\n",
    "    for x in data[\"articles\"]:\n",
    "        paper.append(\n",
    "            [\n",
    "                x[\"title\"],\n",
    "                x[\"abstract\"],\n",
    "                x[\"citing_paper_count\"],\n",
    "                x[\"publication_year\"],\n",
    "                x[\"html_url\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    total_results = data[\"total_records\"]\n",
    "    if total_results > offset + RESULTS_LIMIT:\n",
    "        paper.extend(search_on_ieee_xplore(query,  offset + RESULTS_LIMIT))\n",
    "    \n",
    "    return paper\n",
    "\n",
    "\n",
    "paper_ieee_xplore = search_on_ieee_xplore(\n",
    "    '(\"All Metadata\":Automotive OR \"All Metadata\":Vehicle OR \"All Metadata\":SDV) AND '\n",
    "    '(\"All Metadata\":SOA OR \"All Metadata\":\"Service-Oriented Architecture\") '\n",
    "    'NOT (\"Document Title\":Survey) '\n",
    "    'NOT (\"Document Title\":Study) '\n",
    "    'NOT (\"Document Title\":Review) '\n",
    "    'NOT (\"Document Title\":Comparison)'\n",
    ")\n",
    "\n",
    "with open(\"paper_ieee_xplore.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    headings = [\"title\", \"abstract\", \"citations\", \"year\", \"source\"]\n",
    "\n",
    "    writer.writerow(headings)\n",
    "\n",
    "    for paper in paper_ieee_xplore:\n",
    "        writer.writerow(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_on_dblp(query, offset = 0):\n",
    "    paper = []\n",
    "\n",
    "    options = {\n",
    "        \"q\": query,\n",
    "        \"format\": \"json\",\n",
    "        \"h\": RESULTS_LIMIT,\n",
    "        \"f\": offset\n",
    "    }\n",
    "    r = requests.get(f\"https://dblp.org/search/publ/api?{urlencode(options)}\").json()\n",
    "\n",
    "    hits = r.get(\"result\").get(\"hits\").get(\"hit\")\n",
    "    for hit in hits:\n",
    "        info = hit.get(\"info\")\n",
    "\n",
    "        if int(info.get(\"year\")) >= int(YEAR_START):\n",
    "            paper.append([info.get(\"title\"), \"\", 0, info.get(\"year\"), info.get(\"url\")])\n",
    "    \n",
    "    total_results = int(r.get(\"result\").get(\"hits\").get(\"@total\"))\n",
    "    if total_results > offset + RESULTS_LIMIT:\n",
    "        paper.extend(search_on_dblp(query,  offset + RESULTS_LIMIT))\n",
    "    \n",
    "    return paper\n",
    "\n",
    "\n",
    "paper_dblp = search_on_dblp(\"Automotive|Vehicle|SDV SOA\")\n",
    "paper_dblp.extend(search_on_dblp(\"Automotive|Vehicle|SDV Service Oriented\"))\n",
    "\n",
    "with open(\"paper_dblp.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    headings = [\"title\", \"abstract\", \"citations\", \"year\", \"source\"]\n",
    "    writer.writerow(headings)\n",
    "\n",
    "    paper_written = set()\n",
    "    for paper in paper_dblp:\n",
    "        if paper[4] in paper_written:\n",
    "            continue\n",
    "\n",
    "        writer.writerow(paper)\n",
    "\n",
    "        paper_written.add(paper[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doi_target(url):\n",
    "    r = requests.get(url, allow_redirects=False)\n",
    "    \n",
    "    return r.headers[\"Location\"]\n",
    "\n",
    "\n",
    "def get_dblp_paper_info(url):\n",
    "    regex = re.compile(r\"https:\\/\\/dblp\\.org\\/rec\\/([A-Za-z0-9\\/\\-]+)\")\n",
    "    id = regex.search(url)\n",
    "\n",
    "    if url is None:\n",
    "        raise ValueError(\"unable to parse DBLP identifier\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(\"error while fetching information from DBLP\")\n",
    "\n",
    "    soup = BS(response.content)\n",
    "    elem = soup.find(\"li\", {\"id\": id.group(1)})\n",
    "\n",
    "    if elem is not None:\n",
    "        sub_elem = elem.find(\"div\", {\"class\": \"box\"}).find(\"img\")\n",
    "        \n",
    "        paper_type = None\n",
    "        if sub_elem is not None:\n",
    "            paper_type = sub_elem.get(\"title\")\n",
    "\n",
    "        sub_elem = (\n",
    "            elem\n",
    "            .find(\"nav\", {\"class\": \"publ\"})\n",
    "            .find(\"li\", {\"class\": \"drop-down\"})\n",
    "            .find(\"div\", {\"class\": \"head\"})\n",
    "            .find(\"a\")\n",
    "        )\n",
    "\n",
    "        paper_url = None\n",
    "        if sub_elem is not None:\n",
    "            if (\n",
    "                paper_type == \"Books and Theses\" or\n",
    "                paper_type == \"Data and Artifacts\" or\n",
    "                paper_type == \"Informal and Other Publications\"\n",
    "            ):\n",
    "                paper_url = sub_elem.get(\"href\")\n",
    "            else:\n",
    "                paper_url = get_doi_target(sub_elem.get(\"href\"))\n",
    "\n",
    "        return paper_type, paper_url\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_ieee_paper_info(url):\n",
    "    regex = re.compile(r\"https:\\/\\/ieeexplore\\.ieee\\.org\\/document\\/([0-9]+)\")\n",
    "    id = regex.search(url)\n",
    "\n",
    "    x = XPLORE(KEY_IEEE_XPLORE)\n",
    "\n",
    "    x.articleNumber(id.group(1))\n",
    "    x.dataType(\"json\")\n",
    "\n",
    "    data = x.callAPI()\n",
    "    data = json.loads(data)\n",
    "\n",
    "    return (\n",
    "        data[\"articles\"][0][\"abstract\"],\n",
    "        data[\"articles\"][0][\"citing_paper_count\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_scopus_paper_info(url):\n",
    "    # try to find a DOI\n",
    "    regex = re.compile(r\"10[.][0-9]{4,}\\/(?:[.]?[A-Za-z0-9-_]+)*\")\n",
    "    id = regex.search(url)\n",
    "\n",
    "    if id is None:\n",
    "        # try to find Scopus ID\n",
    "        regex = re.compile(r\"S[0-9]+\")\n",
    "        id = regex.search(url)\n",
    "\n",
    "        if id is None:\n",
    "            return None, None\n",
    "    \n",
    "    try:\n",
    "        ab = AbstractRetrieval(id.group(), refresh=False, view=\"FULL\")\n",
    "    \n",
    "        return ab.description, ab.citedby_count\n",
    "    except:    \n",
    "        return None, None\n",
    "\n",
    "\n",
    "pybliometrics.scopus.init(keys=[KEY_ELSEVIER])\n",
    "\n",
    "paper = []\n",
    "with open(\"paper_dblp.csv\", \"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    next(reader)  # skip the headers\n",
    "\n",
    "    for x in reader:\n",
    "        info = get_dblp_paper_info(x[4])\n",
    "\n",
    "        if info[0] == \"Data and Artifacts\":\n",
    "            paper.append([x[0], \"Data and Artifacts\", \"Data and Artifacts\", x[3], info[1]])\n",
    "            continue\n",
    "\n",
    "        domain = urlparse(info[1]).netloc\n",
    "        if domain == \"ieeexplore.ieee.org\":\n",
    "            paper_info = get_ieee_paper_info(info[1])\n",
    "\n",
    "            paper.append([x[0], paper_info[0], paper_info[1], x[3], info[1]])\n",
    "\n",
    "        else:\n",
    "            paper_info = get_scopus_paper_info(info[1])\n",
    "\n",
    "            if paper_info[0] is not None:\n",
    "                paper.append([x[0], paper_info[0], paper_info[1], x[3], info[1]])\n",
    "            else:\n",
    "                paper.append([x[0], \"MANUAL\", \"MANUAL\", x[3], info[1]])\n",
    "    \n",
    "    with open(\"paper_dblp_enriched.csv\", \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        headings = [\"title\", \"abstract\", \"citations\", \"year\", \"source\"]\n",
    "\n",
    "        writer.writerow(headings)\n",
    "\n",
    "        for x in paper:\n",
    "            writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.mdpi.com/2624-800X/2/3/37\n",
      "Enter abstract:\n",
      "Enter citation count:\n"
     ]
    }
   ],
   "source": [
    "paper = []\n",
    "with open(\"paper_dblp_enriched.csv\", \"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    next(reader)  # skip the headers\n",
    "\n",
    "    for x in reader:\n",
    "        if x[1] == \"MANUAL\" and x[2] == \"MANUAL\":\n",
    "            print(x[4])\n",
    "\n",
    "            print(\"Enter abstract:\")\n",
    "            abstract = input()\n",
    "            \n",
    "            print(\"Enter citation count:\")\n",
    "            citation_count = input()\n",
    "\n",
    "            paper.append([x[0], abstract, citation_count, x[3], x[4]])\n",
    "        else:\n",
    "            paper.append(x)\n",
    "\n",
    "with open(\"paper_dblp_enriched_manually.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    headings = [\"title\", \"abstract\", \"citations\", \"year\", \"source\"]\n",
    "\n",
    "    writer.writerow(headings)\n",
    "\n",
    "    for x in paper:\n",
    "        writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "def get_imported_paper(file):\n",
    "    regex = re.compile(r\"10[.][0-9]{4,}\\/(?:[.]?[A-Za-z0-9]+)*\")\n",
    "\n",
    "    dois = set()\n",
    "    try:\n",
    "        with open(file, \"r\", newline=\"\") as file:\n",
    "            reader = csv.reader(file)\n",
    "\n",
    "            next(reader)  # skip the headers\n",
    "\n",
    "            for x in reader:\n",
    "                doi = regex.search(x[4])\n",
    "\n",
    "                if doi:\n",
    "                    dois.add(doi.group())\n",
    "                else:\n",
    "                    print(f\"error while parsing doi for entry with source {x[4]}\")\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    return dois\n",
    "\n",
    "\n",
    "def get_cite_count_from_acm(doi):\n",
    "    url = f\"https://dl.acm.org/doi/{doi}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 403:\n",
    "        raise ValueError(\"blocked by ACM\")\n",
    "    elif response.status_code == 404:\n",
    "        return \"E404\"\n",
    "    elif response.status_code != 200:\n",
    "        print(\"other error while fetching cite count from ACM\")\n",
    "\n",
    "    soup = BS(response.content)\n",
    "    elem = soup.find(\"span\", {\"class\": \"citation\"})\n",
    "\n",
    "    if elem is not None:\n",
    "        elem = elem.find(\"span\", {\"class\": None})\n",
    "        if elem is not None:\n",
    "            return elem.text\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "dois_imported_paper = get_imported_paper(\"paper_acm.csv\")\n",
    "\n",
    "library = bibtexparser.parse_file(\"paper_acm.bib\")\n",
    "\n",
    "with open(\"paper_acm.csv\", \"a+\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    if len(dois_imported_paper) == 0:\n",
    "        headings = [\"title\", \"abstract\", \"citations\", \"year\", \"source\"]\n",
    "        writer.writerow(headings)\n",
    "    \n",
    "    completed = True\n",
    "    for x in library.entries:\n",
    "        if \"proceedings\" in x.fields_dict[\"title\"].value.lower():\n",
    "            continue\n",
    "\n",
    "        if x.key in dois_imported_paper:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cite_count = get_cite_count_from_acm(x.key)\n",
    "        except ValueError:\n",
    "            print(\"blocked by ACM - continue later\")\n",
    "            completed = False\n",
    "            break\n",
    "        \n",
    "        writer.writerow(\n",
    "            [\n",
    "                x.fields_dict[\"title\"].value,\n",
    "                x.fields_dict[\"abstract\"].value if \"abstract\" in x.fields_dict else \"\",\n",
    "                cite_count if cite_count is not None else \"-\",\n",
    "                x.fields_dict[\"year\"].value,\n",
    "                x.fields_dict[\"url\"].value\n",
    "                    if \"url\" in x.fields_dict else f\"https://dl.acm.org/doi/{x.key}\"\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    if completed:\n",
    "        print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_relevant_subject_area(eid):\n",
    "    ab = AbstractRetrieval(eid, refresh=False, view=\"FULL\")\n",
    "    \n",
    "    for sa in ab.subject_areas:\n",
    "        if sa.abbreviation == \"ENGI\" or sa.abbreviation == \"COMP\":\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "s = ScopusSearch(\n",
    "    f'TITLE-ABS-KEY((Automotive OR Vehicle OR SDV) AND (SOA OR \"Service-Oriented Architecture\")) '\n",
    "    f'AND PUBYEAR > {int(YEAR_START) - 1} AND NOT TITLE (Survey OR Study OR Review OR Comparison)',\n",
    "    refresh=False,\n",
    "    subscriber=True\n",
    ")\n",
    "\n",
    "pybliometrics.scopus.init(keys=[KEY_ELSEVIER])\n",
    "\n",
    "with open(\"paper_scopus.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    headings = [\"title\", \"abstract\", \"citations\", \"year\", \"source\"]\n",
    "\n",
    "    writer.writerow(headings)\n",
    "    for paper in s.results:\n",
    "        if not is_in_relevant_subject_area(paper.eid):\n",
    "            continue\n",
    "\n",
    "        date = datetime.strptime(paper.coverDate, \"%Y-%m-%d\")\n",
    "\n",
    "        writer.writerow(\n",
    "            [\n",
    "                paper.title,\n",
    "                paper.description,\n",
    "                paper.citedby_count,\n",
    "                date.strftime(\"%Y\"),\n",
    "                f\"https://doi.org/{paper.doi}\" if paper.doi is not None else \"-\",\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IEEE Xplore</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBLP</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACM</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scopus</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source  count\n",
       "0  IEEE Xplore    273\n",
       "1         DBLP     65\n",
       "2          ACM    135\n",
       "3       Scopus    237"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_papers_ieee = pd.read_csv(\"papers_ieee_xplore.csv\", dtype={\"citations\": \"int64\"})\n",
    "df_papers_dblp = pd.read_csv(\"papers_dblp_enriched_manually.csv\", dtype={\"citations\": \"int64\"})\n",
    "df_papers_acm = pd.read_csv(\"papers_acm.csv\", dtype={\"citations\": \"int64\"})\n",
    "df_papers_scopus = pd.read_csv(\"papers_scopus.csv\", dtype={\"citations\": \"int64\"})\n",
    "\n",
    "# for deduplication we need to remove the trailing dot from dblp entries\n",
    "df_papers_dblp[\"title\"] = df_papers_dblp[\"title\"].str[:-1]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "    \"source\": [\"IEEE Xplore\", \"DBLP\", \"ACM\", \"Scopus\"],\n",
    "    \"count\": [\n",
    "            len(df_papers_ieee.index),\n",
    "            len(df_papers_dblp.index),\n",
    "            len(df_papers_acm.index),\n",
    "            len(df_papers_scopus.index)\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 710\n",
      "Duplicates: 116\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_papers_ieee, df_papers_dblp, df_papers_acm, df_papers_scopus])\n",
    "\n",
    "count = len(df.index)\n",
    "\n",
    "print(f\"Total: {count}\")\n",
    "\n",
    "# sort by citation count first to keep the highest citation count while deduplicating\n",
    "df = df.sort_values(by=\"citations\", ascending=False)\n",
    "\n",
    "df = df[~df[\"source\"].duplicated() | df[\"source\"].eq(\"-\")]\n",
    "df = df.drop_duplicates(subset=[\"title\"])\n",
    "\n",
    "duplicates = count - len(df.index)\n",
    "\n",
    "print(f\"Duplicates: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results: 136\n"
     ]
    }
   ],
   "source": [
    "# remove preprints\n",
    "df = df[~df[\"source\"].str.contains(\"arXiv\")]\n",
    "\n",
    "# remove findings with too little citations\n",
    "df = df[(df[\"citations\"] >= 5)]\n",
    "\n",
    "df.to_csv(\"papers_for_manual_screening_based_on_title.csv\", index=False)  \n",
    "\n",
    "count = len(df.index)\n",
    "\n",
    "print(f\"Filtered results: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed during manual screening based on title: 112\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"papers_manually_screened_based_on_title.csv\")\n",
    "\n",
    "removed = count - len(df.index)\n",
    "\n",
    "print(f\"Removed during manual screening based on title: {removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed during manual screening based on abstract: 14\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"papers_manually_screened_based_on_abstract.csv\")\n",
    "\n",
    "removed = count - removed - len(df.index)\n",
    "\n",
    "print(f\"Removed during manual screening based on abstract: {removed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
